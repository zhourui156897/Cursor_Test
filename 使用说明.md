# 第二大脑 v0.3 — 关闭、保存、再次启动

## 一、如何关闭（结束当前进程）

### 方式 A：用 Makefile（推荐）

在项目根目录执行：

```bash
cd /Users/old/dierdanao
make stop
```

会停止：后端 (uvicorn)、前端 (Vite)、以及 Docker 里的 Milvus/Neo4j 等。

### 方式 B：手动关

- **后端**：在运行后端的终端里按 `Ctrl + C`；或执行  
  `pkill -f "uvicorn app.main:app"`
- **前端**：在运行前端的终端里按 `Ctrl + C`；或执行  
  `pkill -f "vite"`
- **Docker**（若用了）：  
  `cd /Users/old/dierdanao && docker compose down`

关掉上述进程后，当前「运行状态」就结束了，不会自动保存到任何地方，下次需要重新启动。

---

## 二、如何保存当前进度（下次能接着干）

你要保存的主要是两类东西：**代码** 和 **数据/配置**。

### 1. 代码（项目文件）

- 代码都在目录 `/Users/old/dierdanao` 里，**保存文件 = 进度已在磁盘上**（Cursor 里 Cmd+S 或自动保存即可）。
- 若已用 Git 并推过 GitHub，建议每次告一段落执行一次：
  ```bash
  cd /Users/old/dierdanao
  git add .
  git commit -m "v0.3 雏形：同步范围、Agent 写知识库、数据流说明等"
  git push
  ```
  这样进度在本地 + 远程都有，换电脑或重装也能拉下来继续。

### 2. 数据与配置（实体、审核、Obsidian、设置）

- **SQLite 数据库**：默认在 `~/.dierdanao/data/`（或 `.env` 里 `DATA_DIR` 指向的目录）。只要不删这个目录，实体、审核队列、用户等都会保留。
- **Obsidian 笔记**：在你的 Vault 目录（如 `~/Documents/ObsidianVault`），由 Obsidian 和你自己的备份负责。
- **配置**：`backend/config/user_config.yaml`（LLM、标签、路径等）和项目根目录 `.env`。保留这些文件 = 保留配置。

**可选：整份备份**

```bash
cd /Users/old/dierdanao
make backup
```

会在 `backups/` 下生成带时间戳的目录，里面包含当时的配置和数据文件路径说明，可按需把 `~/.dierdanao/data` 里的 db 也拷进去。

---

## 三、下次如何再次启动

**前提**：确保数据目录可写（见下方「五、最佳实践」），否则后端会启动失败并提示修复命令。

### 方式 A：用 Makefile 一键启动

```bash
cd /Users/old/dierdanao
make start
```

会依次：启动 Docker（Milvus、Neo4j 等）→ 后台启动后端 → 后台启动前端。  
完成后：

- 前端：浏览器打开 **http://localhost:3000**（若未改 `FRONTEND_PORT`）
- 后端文档：**http://localhost:8000/docs**

（若你平时是手动 `npm run dev`，前端可能在 **5173**，以实际终端里提示的为准。）

### 方式 B：手动分步启动（便于看日志）

1. **Docker（若需要 Milvus/Neo4j）**

   ```bash
   cd /Users/old/dierdanao
   docker compose up -d
   ```

2. **后端**

   ```bash
   cd /Users/old/dierdanao/backend
   source .venv/bin/activate
   uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
   ```

   保持终端不关；要停就 `Ctrl+C`。

3. **前端**（新开一个终端）

   ```bash
   cd /Users/old/dierdanao/frontend
   npm run dev
   ```

   浏览器打开终端里显示的地址（一般是 http://localhost:5173）。

关的时候：先在后端、前端各自终端里 `Ctrl+C`，再在项目根目录执行 `docker compose down`（若用了 Docker）。

---

## 四、小结

| 想做什么       | 怎么做 |
|----------------|--------|
| **关掉当前运行** | `make stop` 或 各终端 `Ctrl+C` + `docker compose down` |
| **保存进度**     | 代码：保存文件 + 可选 `git commit && git push`；数据：不删 `~/.dierdanao/data` 和 `user_config.yaml`；可选 `make backup` |
| **下次继续**     | `make start` 或 按上面「方式 B」分步启动后端 + 前端（+ Docker） |

按上述方式关闭、保存、再启动，就可以在「雏形第一版」的基础上随时停、随时接着用。

---

## 五、最佳实践：数据目录必须可写

**原则**：数据目录（默认 `~/.dierdanao/data`）必须在**启动前**对当前用户可写，否则后端不应启动或会明确报错，避免出现「能打开页面但智能对话报 500」的差体验。

- **启动时**：后端在初始化数据库前会检查数据目录是否可写；若不可写，会直接报错并退出，错误信息中会给出修复命令。
- **若曾遇到智能对话报 HTTP 500 或 503**：多半是数据目录只读。在终端执行一次（路径以你实际使用的数据目录为准）：
  ```bash
  chmod -R u+rwx ~/.dierdanao/data
  ```
  若通过 `.env` 中 `DATA_DIR` 指定了别的目录，请对**该目录**执行上述 `chmod`。执行后**重启后端**即可恢复正常。
- **不建议**：不要依赖「只读时仍能回复但不存历史」的降级行为；应以**修复权限后再启动**为准，保证对话历史与实体等数据正常持久化。

---

## 六、聊天报错「LLM 服务不可用」

聊天/RAG 会先检查 LLM 是否可用（请求配置中的 `/models` 接口），失败则提示「LLM 服务不可用，无法生成回答。请检查 LLM API 配置。」

**请按下面检查：**

1. **是否已配置 LLM**
   - 打开 `backend/config/user_config.yaml`（若没有，从 `user_config.example.yaml` 复制一份）。
   - 确保存在 `llm` 段，并至少填写：
     - **OpenAI**：`api_url: "https://api.openai.com/v1"`、`api_key: "sk-..."`、`model: "gpt-4o"` 等。
     - **本地 Ollama**：`api_url: "http://localhost:11434/v1"`、`model: "qwen2.5"`，且本机已启动 Ollama 并拉好模型。
   - 也可在前端 **设置** 页填写 LLM API 地址与 Key，保存后会写回 `user_config.yaml`。

2. **API Key 与地址是否正确**
   - OpenAI：Key 以 `sk-` 开头，且未过期；`api_url` 为 `https://api.openai.com/v1`（或你用的代理地址）。
   - 若用代理或自建端点，确保 `api_url` 指向实际可访问的 base URL。

3. **网络与进程**
   - 本机可访问外网（OpenAI）或本机 11434 端口（Ollama）。
   - 若用 Ollama，终端执行 `ollama list` 确认服务在跑，且配置的 `model` 已存在。

修改配置后**重启后端**再试聊天；Settings 里保存的配置会热加载，但若改了 `user_config.yaml` 的路径或首次添加 `llm`，建议重启一次。

---

## 七、Embedding 与 Milvus 维度

修改 **LLM/Embedding 模型**（在设置中或配置里）时，**embedding 维度**必须与当前 Milvus 集合一致，否则写入向量会报错、语义搜索无法使用。

- 若你曾更换过 embedding 模型或修改过维度，且出现「嵌入失败」「向量检索不可用」等提示，请检查设置中的 **embedding 维度** 与 Milvus 中已建集合的维度是否一致。
- 首次使用或重建环境时，可先初始化/重建 Milvus 集合（或清空向量库后重新审核实体），使维度与当前配置一致。

---

## 八、维护与安装包同步（给维护者）

- **后端依赖变更**：修改 `backend/pyproject.toml` 后，在 backend 的 venv 中执行 `pip install -e .`，再执行 `pip freeze --exclude-editable > requirements.txt`，将 `requirements.txt` 中与项目直接依赖无关的包删掉，保留与 pyproject 一致的核心依赖并提交，以便另一台 Mac 用 `pip install -r requirements.txt` 复现。
- **前端**：保持 `package-lock.json` 提交到仓库，另一台使用 `npm ci` 安装。
- **安装文档**：代码或启动方式、环境要求有变更时，同步更新 `docs/在另一台Mac上完整安装.md`。
